# -*- coding: utf-8 -*-
"""Homework3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZT9zk9x-Aq-TA3SRIfvWs1f-0v_Yzq6i
"""

import gzip
from collections import defaultdict
import math
import scipy.optimize
from sklearn import svm
import numpy
import string
import random
import string
from sklearn import linear_model

import warnings
warnings.filterwarnings("ignore")

def assertFloat(x):
    assert type(float(x)) == float

def assertFloatList(items, N):
    assert len(items) == N
    assert [type(float(x)) for x in items] == [float]*N

def readGz(path):
    for l in gzip.open(path, 'rt'):
        yield eval(l)

def readCSV(path):
    f = gzip.open(path, 'rt')
    f.readline()
    for l in f:
        u,b,r = l.strip().split(',')
        r = int(r)
        yield u,b,r

answers = {}

# Some data structures that will be useful

allRatings = []
for l in readCSV("train_Interactions.csv.gz"):
    allRatings.append(l)

len(allRatings)

ratingsTrain = allRatings[:190000]
ratingsValid = allRatings[190000:]
ratingsPerUser = defaultdict(list)
ratingsPerItem = defaultdict(list)
for u,b,r in ratingsTrain:
    ratingsPerUser[u].append((b,r))
    ratingsPerItem[b].append((u,r))

##################################################
# Read prediction                                #
##################################################

# Copied from baseline code
bookCount = defaultdict(int)
totalRead = 0

for user,book,_ in readCSV("train_Interactions.csv.gz"):
    bookCount[book] += 1
    totalRead += 1

mostPopular = [(bookCount[x], x) for x in bookCount]
mostPopular.sort()
mostPopular.reverse()

return1 = set()
count = 0
for ic, i in mostPopular:
    count += ic
    return1.add(i)
    if count > totalRead/2: break

### Question 1

# Create 2 data structures, one is all the book ids in the dataset, one is all the books each user has read

all_book_ids = [b for u, b, r in allRatings]
itemsPerUser = defaultdict(list)
for u,b,r in ratingsTrain:
    itemsPerUser[u].append(b)

def sample_book(arr):
    return random.choice(arr)

sample_book(all_book_ids)

negativeRatingsValid = []
for user, book, rating in ratingsValid:
    passed = True
    random_book = None
    while passed:
        random_book = sample_book(all_book_ids)
        if random_book not in itemsPerUser[user]:
            passed = False
    negativeRatingsValid.append((user, random_book, -1))

newValid = ratingsValid + negativeRatingsValid

len(newValid)

predictions = []
for u, b, r in newValid:
  if b in return1:
    predictions.append((u, b, 1))
  else:
    predictions.append((u, b, 0))

labels = []
for u, b, r in newValid:
  if b in itemsPerUser[u]:
    labels.append((u, b, 1))
  else:
    labels.append((u, b, 0))

predictions[0][2]

# Finding Accuracy
num_correct = 0
for i in range(len(predictions)):
    predict_rating = predictions[i][2]
    real_rating = labels[i][2]
    if predict_rating == real_rating:
        num_correct += 1

acc1 = num_correct / len(predictions)

answers['Q1'] = acc1

answers['Q1']

assertFloat(answers['Q1'])

### Question 2

def create_return1(ratio):
    return1 = set()
    count = 0
    for ic, i in mostPopular:
        count += ic
        return1.add(i)
        if count > math.floor(totalRead * ratio): break
    return return1

def get_acc():
    # Get Predictions
    predictions = []
    for u, b, r in newValid:
        if b in return1:
            predictions.append((u, b, 1))
        else:
            predictions.append((u, b, 0))
    
    # Get Labels
    labels = []
    for u, b, r in newValid:
        if b in itemsPerUser[u]:
            labels.append((u, b, 1))
        else:
            labels.append((u, b, 0))
    
    # Finding Accuracy
    num_correct = 0
    for i in range(len(predictions)):
        predict_rating = predictions[i][2]
        real_rating = labels[i][2]
        if predict_rating == real_rating:
            num_correct += 1

    acc = num_correct / len(predictions)
    return acc

# Find best ratio
ratios = [.1, .2, .3, .4, .5, .6, .7, .8, .9, 1]
accs = []

threshold = -1
acc2 = -1

for r in ratios:
    return1 = create_return1(r)
    acc = get_acc()
    accs.append((r, acc))
    if acc > acc2:
        acc2 = acc
        threshold = r

answers['Q2'] = [threshold, acc2]

answers['Q2']

assertFloat(answers['Q2'][0])
assertFloat(answers['Q2'][1])

### Question 3/4

def Jaccard(s1, s2):
    numer = len(s1.intersection(s2))
    denom = len(s1.union(s2))
    if denom == 0:
        return 0
    return numer / denom

allUsersIds = [u for u, b, r in allRatings]

# Creating usersPerItem
usersPerItem = defaultdict(list)
for u,b,r in allRatings:
    usersPerItem[b].append(u)

user_id = allUsersIds[0]
book_id = itemsPerUser[user_id][0]
user_id, book_id

# itemsPerUser['u67805239']
# usersPerItem['b61372131']

s1 = set(['dog', 'cat', 'oyster'])
s2 = ['dog', 'gown', 'little']
s1.intersection(s2)

def find_users(books):
    users = set()
    for b in books:
        users_for_book = usersPerItem[b]
        users.update(users_for_book)
    return users

def mostSimilar(i, b):
    
    users_same_book = set(usersPerItem[b])
    books_by_user = itemsPerUser[i]

    users_diff_book = find_users(books_by_user)

    return Jaccard(users_same_book, users_diff_book)

    # for i2, b, r in newValid:
    #     if i2 == i: continue
    #     sim = Jaccard(users_same_book, users_diff_book)
    #     #sim = Pearson(i, i2) # Could use alternate similarity metrics straightforwardly
    #     similarities.append((sim,i2))
    # similarities.sort(reverse=True)
    # return similarities[:-1]

mostSimilar(user_id, book_id)

similarities = dict()
for u, b, r in newValid:
    similarity_score = mostSimilar(u, b)
    similarities[(u, b)] = similarity_score

import statistics
similarity_mean = statistics.mean(similarities.values())

def get_acc_3():
    # Get Predictions
    predictions = []
    for u, b, r in newValid:
        if similarities[(u, b)] > similarity_mean:
            predictions.append((u, b, 1))
        else:
            predictions.append((u, b, 0))
    
    # Get Labels
    labels = []
    for u, b, r in newValid:
        if b in itemsPerUser[u]:
            labels.append((u, b, 1))
        else:
            labels.append((u, b, 0))
    
    # Finding Accuracy
    num_correct = 0
    for i in range(len(predictions)):
        predict_rating = predictions[i][2]
        real_rating = labels[i][2]
        if predict_rating == real_rating:
            num_correct += 1

    acc = num_correct / len(predictions)
    return acc

def get_acc_4():
    # Get Predictions
    predictions = []
    for u, b, r in newValid:
        if b in return1 and similarities[(u, b)] > similarity_mean:
            predictions.append((u, b, 1))
        else:
            predictions.append((u, b, 0))
    
    # Get Labels
    labels = []
    for u, b, r in newValid:
        if b in itemsPerUser[u]:
            labels.append((u, b, 1))
        else:
            labels.append((u, b, 0))
    
    # Finding Accuracy
    num_correct = 0
    for i in range(len(predictions)):
        predict_rating = predictions[i][2]
        real_rating = labels[i][2]
        if predict_rating == real_rating:
            num_correct += 1

    acc = num_correct / len(predictions)
    return acc

return1 = create_return1(.3)

acc3 = get_acc_3()
acc4 = get_acc_4()

answers['Q3'] = acc3
answers['Q4'] = acc4

answers['Q3'], answers['Q4']

assertFloat(answers['Q3'])
assertFloat(answers['Q4'])

### Question 5

all_similarities = dict()
for u, b, r in allRatings:
    similarity_score = mostSimilar(u, b)
    all_similarities[(u, b)] = similarity_score

len(all_similarities)

predictions = open("predictions_Read.csv", 'w')
for l in open("pairs_Read.csv"):
    if l.startswith("userID"):
        predictions.write(l)
        continue
    u,b = l.strip().split(',')
    # (etc.) my code
    if (u, b) in all_similarities:
        if (b in return1) and (all_similarities[(u, b)] > similarity_mean):
            predictions.write(u + ',' + b + ",1\n")
        else:
            predictions.write(u + ',' + b + ",0\n")
    else:
        if (b in return1):
            predictions.write(u + ',' + b + ",1\n")
        else:
            predictions.write(u + ',' + b + ",0\n")
predictions.close()

answers['Q5'] = "I confirm that I have uploaded an assignment submission to gradescope"

assert type(answers['Q5']) == str

##################################################
# Category prediction (CSE158 only)              #
##################################################

### Question 6

data = []

for d in readGz("train_Category.json.gz"):
    data.append(d)

data[0]

reviewsTrain = data[:90000]
reviewsValid = data[90000:]

wordCount = defaultdict(int)
punctuation = set(string.punctuation)
for d in data:
    r = ''.join([c for c in d['review_text'].lower() if not c in punctuation])
    for w in r.split():
        wordCount[w] += 1

len(wordCount)

counts = [(wordCount[w], w) for w in wordCount]
counts.sort()
counts.reverse()

answers['Q6'] = counts[:10]

counts[:10]

assert [type(x[0]) for x in answers['Q6']] == [int]*10
assert [type(x[1]) for x in answers['Q6']] == [str]*10

### Question 7

words = [x[1] for x in counts[:1000]]

wordId = dict(zip(words, range(len(words))))
wordSet = set(words)

def feature(datum):
    feat = [0]*len(words)
    r = ''.join([c for c in datum['review_text'].lower() if not c in punctuation])
    for w in r.split():
        if w in words:
            feat[wordId[w]] += 1
    feat.append(1) # offset
    return feat

X = [feature(d) for d in data]
y = [d['rating'] for d in data]

Xtrain = X[:9*len(X)//10]
ytrain = y[:9*len(y)//10]
Xvalid = X[9*len(X)//10:]
yvalid = y[9*len(y)//10:]

import sklearn
mod = sklearn.linear_model.LogisticRegression(fit_intercept=False)
mod.fit(Xtrain,ytrain)

predictions = mod.predict(Xvalid) # Binary vector of predictions
correct = predictions == yvalid # Binary vector indicating which predictions were correct
acc7 = sum(correct) / len(correct)

answers['Q7'] = acc7

answers['Q7']

assertFloat(answers['Q7'])

### Question 8

C = [.0001, .001, .01, .1, 1, 10, 100, 1000, 10000]

bestModel = None
bestVal = None
bestC = None

accList = []
for c in C:
    model = linear_model.LogisticRegression(C=c, class_weight='balanced')
    model.fit(Xtrain, ytrain)
    predictValid = model.predict(Xvalid)

    correct = predictValid == yvalid # Binary vector indicating which predictions were correct
    acc = sum(correct) / len(correct)
    accList.append(acc)
    print("l = " + str(c) + ", accuracy = " + str(acc))

    # Updating best values
    if bestVal == None or acc > bestVal:
        bestVal = acc
        bestModel = model
        bestC = c
acc8 = bestVal

answers['Q8'] = acc8

answers['Q8']

assertFloat(answers['Q8'])

predictions

# Run on test set

predictions = open("predictions_Category.csv", 'w')
pos = 0

for l in open("pairs_Category.csv"):
    if l.startswith("userID"):
        predictions.write(l)
        continue
    u,b = l.strip().split(',')
    # (etc.)

predictions.close()

f = open("answers_hw3.txt", 'w')
f.write(str(answers) + '\n')
f.close()

